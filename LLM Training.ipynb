{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWoD_AOQNVpR",
        "outputId": "fa5752dc-18d3-4f73-f3d7-219a0674ae03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install necessary libraries\n",
        "!pip install -q transformers[torch] datasets evaluate rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Load the dataset from a reliable alternative mirror\n",
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "# This repository contains the exact same 'sentences_allagree' data\n",
        "dataset = load_dataset(\"FinanceMTEB/financial_phrasebank\", split=\"train\")\n",
        "\n",
        "# Step 2.1: Manual Splitting (80/10/10) - Required for 12/12 points!\n",
        "train_testvalid = dataset.train_test_split(test_size=0.2, seed=42)\n",
        "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=42)\n",
        "\n",
        "split_dataset = DatasetDict({\n",
        "    'train': train_testvalid['train'],\n",
        "    'test': test_valid['test'],\n",
        "    'valid': test_valid['train']\n",
        "})\n",
        "\n",
        "print(\"Dataset successfully loaded and split!\")\n",
        "print(split_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "qLezlQOoO3CV",
        "outputId": "0e1ad968-f122-4df7-b777-ec74145d525f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset successfully loaded and split!\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label_text', 'label'],\n",
            "        num_rows: 1011\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label_text', 'label'],\n",
            "        num_rows: 127\n",
            "    })\n",
            "    valid: Dataset({\n",
            "        features: ['text', 'label_text', 'label'],\n",
            "        num_rows: 126\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Data Cleaning (Updated for the 'text' column name)\n",
        "import re\n",
        "\n",
        "def clean_financial_text(examples):\n",
        "    cleaned_texts = []\n",
        "    # Changed from examples[\"sentence\"] to examples[\"text\"]\n",
        "    for text in examples[\"text\"]:\n",
        "        # 1. Remove stock tickers like $AAPL\n",
        "        text = re.sub(r'\\$\\w+', '', text)\n",
        "        # 2. Remove URLs\n",
        "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "        # 3. Remove non-alphanumeric (keep basic punctuation)\n",
        "        text = re.sub(r'[^\\w\\s\\.\\,\\?\\!]', '', text)\n",
        "        # 4. Remove extra whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        cleaned_texts.append(text)\n",
        "\n",
        "    # Return as 'text' so it overwrites the original column\n",
        "    return {\"text\": cleaned_texts}\n",
        "\n",
        "# Apply to all splits\n",
        "cleaned_dataset = split_dataset.map(clean_financial_text, batched=True)\n",
        "\n",
        "# Final check\n",
        "print(f\"Sample Cleaned Text: {cleaned_dataset['train'][0]['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "M1BRuFI6Pz-h",
        "outputId": "ba82c9e5-d9f6-4b2c-a489-448652dcc595"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Cleaned Text: The company can not give up palm oil altogether , however .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Get labels from training set to calculate imbalance\n",
        "train_labels = cleaned_dataset['train']['label']\n",
        "\n",
        "# Calculate weights (Professional technique for handling imbalanced data)\n",
        "weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=np.array(train_labels))\n",
        "weights = torch.tensor(weights, dtype=torch.float).to(\"cuda\")\n",
        "\n",
        "print(f\"Calculated Class Weights: {weights}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMdoMF6RXE8i",
        "outputId": "1a469663-0378-4565-8fad-618d3a1e189c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated Class Weights: tensor([2.6124, 0.5444, 1.2814], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Initialize Tokenizer and Model\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "\n",
        "# 1. Load the Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "# 2. Define the mappings (0: neg, 1: neu, 2: pos)\n",
        "# This is crucial for the \"Error Analysis\" section later\n",
        "id2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
        "label2id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
        "\n",
        "# 3. Load the Model with 3 labels\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=3,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "# 4. Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Apply tokenization to our cleaned dataset\n",
        "tokenized_datasets = cleaned_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set the format for PyTorch\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "\n",
        "print(\"Model and Tokenizer are ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "hmmvSR8sQW8b",
        "outputId": "49a794e1-126d-4f04-d9f5-7ce295234bdb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DistilBertForSequenceClassification LOAD REPORT from: distilbert-base-uncased\n",
            "Key                     | Status     | \n",
            "------------------------+------------+-\n",
            "vocab_transform.bias    | UNEXPECTED | \n",
            "vocab_projector.bias    | UNEXPECTED | \n",
            "vocab_layer_norm.weight | UNEXPECTED | \n",
            "vocab_transform.weight  | UNEXPECTED | \n",
            "vocab_layer_norm.bias   | UNEXPECTED | \n",
            "classifier.weight       | MISSING    | \n",
            "pre_classifier.weight   | MISSING    | \n",
            "classifier.bias         | MISSING    | \n",
            "pre_classifier.bias     | MISSING    | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and Tokenizer are ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Define Evaluation Metrics\n",
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "JrF5HupDQBUd",
        "outputId": "8be8b349-b5c3-4f23-98a3-9955d63aa01e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Training Function and Experiments (Final Strategy Fix)\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Define the three configurations to test\n",
        "experiments = [\n",
        "    {\"name\": \"Exp_1\", \"lr\": 2e-5, \"epochs\": 3},\n",
        "    {\"name\": \"Exp_2\", \"lr\": 5e-5, \"epochs\": 3},\n",
        "    {\"name\": \"Exp_3\", \"lr\": 3e-5, \"epochs\": 5}\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for exp in experiments:\n",
        "    print(f\"\\n--- Running {exp['name']}: LR={exp['lr']}, Epochs={exp['epochs']} ---\")\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results_{exp['name']}\",\n",
        "        eval_strategy=\"epoch\",    # Evaluate at the end of every epoch\n",
        "        save_strategy=\"epoch\",    # MATCHING: Save at the end of every epoch\n",
        "        learning_rate=exp['lr'],\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=exp['epochs'],\n",
        "        weight_decay=0.01,\n",
        "        logging_dir='./logs',\n",
        "        load_best_model_at_end=True, # Now allowed because eval and save strategies match\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_datasets[\"train\"],\n",
        "        eval_dataset=tokenized_datasets[\"valid\"],\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    eval_results = trainer.evaluate()\n",
        "    results.append({\n",
        "        \"Experiment\": exp['name'],\n",
        "        \"Learning Rate\": exp['lr'],\n",
        "        \"Epochs\": exp['epochs'],\n",
        "        \"Accuracy\": eval_results['eval_accuracy']\n",
        "    })\n",
        "\n",
        "# Display final comparison table\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\n--- Final Comparison Table ---\")\n",
        "print(df_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hmmvSR8sQW8b",
        "outputId": "49a794e1-126d-4f04-d9f5-7ce295234bdb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`logging_dir` is deprecated and will be removed in v5.2. Please set `TENSORBOARD_LOGGING_DIR` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Exp_1: LR=2e-05, Epochs=3 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias'].\n",
            "There were unexpected keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.beta', 'distilbert.embeddings.LayerNorm.gamma'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`logging_dir` is deprecated and will be removed in v5.2. Please set `TENSORBOARD_LOGGING_DIR` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Exp_2: LR=5e-05, Epochs=3 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias'].\n",
            "There were unexpected keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.beta', 'distilbert.embeddings.LayerNorm.gamma'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`logging_dir` is deprecated and will be removed in v5.2. Please set `TENSORBOARD_LOGGING_DIR` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Exp_3: LR=3e-05, Epochs=5 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias'].\n",
            "There were unexpected keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.beta', 'distilbert.embeddings.LayerNorm.gamma'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Comparison Table ---\n",
            "  Experiment  Learning Rate  Epochs  Accuracy\n",
            "0      Exp_1        0.00002       3  0.944444\n",
            "1      Exp_2        0.00005       3  0.960317\n",
            "2      Exp_3        0.00003       5  0.960317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import Trainer\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # Apply the weights calculated in the previous cell\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "8H9geYbBXXqZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting Learning Curves from the final experiment\n",
        "history = trainer.state.log_history\n",
        "train_loss = [x['loss'] for x in history if 'loss' in x]\n",
        "eval_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss, label='Training Loss', color='blue', lw=2)\n",
        "plt.plot(eval_loss, label='Validation Loss', color='orange', lw=2)\n",
        "plt.title('Model Convergence: Training vs. Validation Loss')\n",
        "plt.xlabel('Training Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "vCXO9EYoXfUn",
        "outputId": "3380cb76-a110-4384-9d41-9390e286c6fe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Baseline Comparison\n",
        "from transformers import AutoModelForSequenceClassification, Trainer\n",
        "import torch\n",
        "\n",
        "# 1. Load a Fresh (Baseline) Model\n",
        "baseline_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_checkpoint, num_labels=3\n",
        ").to(\"cuda\")\n",
        "\n",
        "# 2. Setup Baseline Trainer for Evaluation\n",
        "baseline_trainer = Trainer(\n",
        "    model=baseline_model,\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# 3. Evaluate Baseline vs Fine-Tuned (the current 'model' variable)\n",
        "print(\"Evaluating Baseline Model...\")\n",
        "baseline_results = baseline_trainer.evaluate()\n",
        "\n",
        "print(\"Evaluating Fine-Tuned Model...\")\n",
        "# Use the trainer from your last experiment run\n",
        "finetuned_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
        "\n",
        "# 4. Create a Comparison Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "methods = ['Baseline (Raw)', 'Fine-Tuned (Yours)']\n",
        "accuracies = [baseline_results['eval_accuracy'], finetuned_results['eval_accuracy']]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "bars = plt.bar(methods, accuracies, color=['gray', 'skyblue'])\n",
        "plt.ylim(0, 1.0)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Impact of Fine-Tuning on Financial Sentiment Analysis')\n",
        "\n",
        "# Add labels on top of bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f'{yval:.2%}', ha='center')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "0kh205w5T9kj",
        "outputId": "72c78a84-4f36-4c19-b54d-65982afbf3cd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DistilBertForSequenceClassification LOAD REPORT from: distilbert-base-uncased\n",
            "Key                     | Status     | \n",
            "------------------------+------------+-\n",
            "vocab_transform.bias    | UNEXPECTED | \n",
            "vocab_projector.bias    | UNEXPECTED | \n",
            "vocab_layer_norm.weight | UNEXPECTED | \n",
            "vocab_transform.weight  | UNEXPECTED | \n",
            "vocab_layer_norm.bias   | UNEXPECTED | \n",
            "classifier.weight       | MISSING    | \n",
            "pre_classifier.weight   | MISSING    | \n",
            "classifier.bias         | MISSING    | \n",
            "pre_classifier.bias     | MISSING    | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Baseline Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Fine-Tuned Model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: Final Evaluation, Confusion Matrix, and Error Analysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# 1. Check if trainer exists (it must be defined in Step 5)\n",
        "if 'trainer' not in locals():\n",
        "    print(\"Error: 'trainer' not found! Please run the training loop in Step 5 first.\")\n",
        "else:\n",
        "    print(\"Generating predictions on the test set... (this may take 10-20 seconds)\")\n",
        "\n",
        "    # 2. Get predictions (This creates 'preds' and 'labels')\n",
        "    predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
        "    preds = np.argmax(predictions.predictions, axis=1)\n",
        "    labels = predictions.label_ids\n",
        "\n",
        "    # 3. Create Confusion Matrix Heatmap\n",
        "    cm = confusion_matrix(labels, preds)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "                xticklabels=id2label.values(),\n",
        "                yticklabels=id2label.values())\n",
        "    plt.title('Confusion Matrix: Financial Sentiment Analysis')\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('Actual Labels')\n",
        "    plt.show()\n",
        "\n",
        "    # 4. Print Professional Classification Report\n",
        "    print(\"\\n--- Detailed Classification Report ---\")\n",
        "    print(classification_report(labels, preds, target_names=id2label.values()))\n",
        "\n",
        "    # 5. Identify Patterns in Errors (Requirement 7)\n",
        "    errors = []\n",
        "    for i, (p, l) in enumerate(zip(preds, labels)):\n",
        "        if p != l:\n",
        "            # Get original text\n",
        "            text = cleaned_dataset[\"test\"][i][\"text\"]\n",
        "            errors.append({\n",
        "                \"Text\": text,\n",
        "                \"Predicted\": id2label[p],\n",
        "                \"Actual\": id2label[l]\n",
        "            })\n",
        "\n",
        "    df_errors = pd.DataFrame(errors)\n",
        "    print(f\"\\nTotal Errors: {len(df_errors)} out of {len(labels)} test samples\")\n",
        "    print(\"\\n--- Error Sample Cases for your Report ---\")\n",
        "    # Using display() for a nicer table in Colab\n",
        "    display(df_errors.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vb9Vrrz_4TTD",
        "outputId": "af20d07a-2c8f-46c4-fdc8-7584f7a31e50"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating predictions on the test set... (this may take 10-20 seconds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Detailed Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.78      0.93      0.85        15\n",
            "     neutral       1.00      0.96      0.98        84\n",
            "    positive       0.93      0.93      0.93        28\n",
            "\n",
            "    accuracy                           0.95       127\n",
            "   macro avg       0.90      0.94      0.92       127\n",
            "weighted avg       0.96      0.95      0.95       127\n",
            "\n",
            "\n",
            "Total Errors: 6 out of 127 test samples\n",
            "\n",
            "--- Error Sample Cases for your Report ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Cell: Inference Pipeline\n",
        "def predict_sentiment(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(\"cuda\")\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "    predicted_class_id = logits.argmax().item()\n",
        "    return id2label[predicted_class_id]\n",
        "\n",
        "# Test it!\n",
        "print(predict_sentiment(\"Company profits rose by 20% this quarter exceeding all expectations.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqK-Z3QqUS7f",
        "outputId": "be9ccd61-c8ac-4b17-dc4f-a41b994f82ea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ]
    }
  ]
}